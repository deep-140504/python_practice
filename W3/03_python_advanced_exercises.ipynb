{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b8cfb3b-5256-488b-838e-75971c2a45ac",
   "metadata": {},
   "source": [
    "#### 1. Implement a python progtam to implement a multi threaded web scrapper the respects robot.txt rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cb8fe23-07be-4628-9f02-01da39b4bf65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping: https://quotes.toscrape.com/\n",
      "Scraping: https://quotes.toscrape.com/tag/love/\n",
      "Scraping: https://quotes.toscrape.com/tag/classic/page/1/\n",
      "Scraping: https://quotes.toscrape.com/author/Thomas-A-Edison\n",
      "Scraping: https://quotes.toscrape.com/tag/inspirational/\n",
      "Scraping: https://quotes.toscrape.com/tag/abilities/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/be-yourself/page/1/\n",
      "Scraping: https://quotes.toscrape.com/page/2/\n",
      "Scraping: https://quotes.toscrape.com/tag/obvious/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/books/\n",
      "Scraping: https://quotes.toscrape.com/tag/reading/\n",
      "Scraping: https://quotes.toscrape.com/tag/miracle/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/success/page/1/\n",
      "Scraping: https://quotes.toscrape.com/login\n",
      "Scraping: https://quotes.toscrape.com/tag/misattributed-eleanor-roosevelt/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/paraphrased/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/simile/page/1/\n",
      "Scraping: https://quotes.toscrape.com/author/J-K-Rowling\n",
      "Scraping: https://quotes.toscrape.com/tag/simile/\n",
      "Scraping: https://quotes.toscrape.com/tag/aliteracy/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/books/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/humor/page/1/\n",
      "Scraping: https://quotes.toscrape.com/author/Eleanor-Roosevelt\n",
      "Scraping: https://quotes.toscrape.com/tag/adulthood/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/live/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/deep-thoughts/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/failure/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/life/\n",
      "Scraping: https://quotes.toscrape.com/author/Marilyn-Monroe\n",
      "Scraping: https://quotes.toscrape.com/tag/life/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/inspirational/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/choices/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/value/page/1/\n",
      "Scraping: https://quotes.toscrape.com/author/Jane-Austen\n",
      "Scraping: https://quotes.toscrape.com/tag/change/page/1/\n",
      "Scraping: https://quotes.toscrape.com/author/Albert-Einstein\n",
      "Scraping: https://quotes.toscrape.com/author/Andre-Gide\n",
      "Scraping: https://quotes.toscrape.com/tag/miracles/page/1/\n",
      "Scraping: https://quotes.toscrape.com/author/Steve-Martin\n",
      "Scraping: https://quotes.toscrape.com/tag/friendship/\n",
      "Scraping: https://quotes.toscrape.com/tag/truth/\n",
      "Scraping: https://quotes.toscrape.com/tag/thinking/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/world/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/friends/\n",
      "Scraping: https://quotes.toscrape.com/tag/humor/\n",
      "Scraping: https://quotes.toscrape.com/tag/edison/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/love/page/1/\n",
      "Scraping: https://quotes.toscrape.com/author/James-Baldwin\n",
      "Scraping: https://quotes.toscrape.com/tag/lack-of-friendship/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/sisters/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/opposite/page/1/\n",
      "Scraping: https://quotes.toscrape.com/author/Friedrich-Nietzsche\n",
      "Scraping: https://quotes.toscrape.com/tag/marriage/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/heartbreak/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/apathy/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/activism/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/love/page/2/\n",
      "Scraping: https://quotes.toscrape.com/tag/friendship/page/1/\n",
      "Scraping: https://quotes.toscrape.com/author/Bob-Marley\n",
      "Scraping: https://quotes.toscrape.com/tag/unhappy-marriage/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/lack-of-love/page/1/\n",
      "Scraping: https://quotes.toscrape.com/author/Pablo-Neruda\n",
      "Scraping: https://quotes.toscrape.com/tag/indifference/page/1/\n",
      "Scraping: https://quotes.toscrape.com/author/Elie-Wiesel\n",
      "Scraping: https://quotes.toscrape.com/tag/philosophy/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/friends/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/girls/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/hate/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/poetry/page/1/\n",
      "Scraping: https://quotes.toscrape.com/author/Mark-Twain\n",
      "Scraping: https://quotes.toscrape.com/tag/reading/page/1/\n",
      "Scraping: https://quotes.toscrape.com/author/C-S-Lewis\n",
      "Scraping: https://quotes.toscrape.com/author/Helen-Keller\n",
      "Scraping: https://quotes.toscrape.com/author/Martin-Luther-King-Jr\n",
      "Scraping: https://quotes.toscrape.com/author/George-Eliot\n",
      "Scraping: https://quotes.toscrape.com/tag/death/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/tea/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/hope/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/inspirational/page/2/\n",
      "Scraping: https://quotes.toscrape.com/author/Douglas-Adams\n",
      "Scraping: https://quotes.toscrape.com/tag/contentment/page/1/\n",
      "Scraping: https://quotes.toscrape.com/author/Dr-Seuss\n",
      "Scraping: https://quotes.toscrape.com/tag/misattributed-john-lennon/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/courage/page/1/\n",
      "Scraping: https://quotes.toscrape.com/author/Allen-Saunders\n",
      "Scraping: https://quotes.toscrape.com/tag/fantasy/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/navigation/page/1/\n",
      "Scraping: https://quotes.toscrape.com/page/3/\n",
      "Scraping: https://quotes.toscrape.com/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/simplicity/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/fate/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/planning/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/plans/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/understand/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/authors/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/books/page/2/\n",
      "Scraping: https://quotes.toscrape.com/author/Madeleine-LEngle\n",
      "Scraping: https://quotes.toscrape.com/author/Haruki-Murakami\n",
      "Scraping: https://quotes.toscrape.com/tag/thought/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/write/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/literature/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/library/page/1/\n",
      "Scraping: https://quotes.toscrape.com/author/J-D-Salinger\n",
      "Scraping: https://quotes.toscrape.com/tag/writing/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/writers/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/difficult/page/1/\n",
      "Scraping: https://quotes.toscrape.com/author/Ernest-Hemingway\n",
      "Scraping: https://quotes.toscrape.com/tag/novelist-quotes/page/1/\n",
      "Scraping: https://quotes.toscrape.com/author/Jorge-Luis-Borges\n",
      "Scraping: https://quotes.toscrape.com/tag/children/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/grown-ups/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/readers/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/seuss/page/1/\n",
      "Scraping: https://quotes.toscrape.com/author/William-Nicholson\n",
      "Scraping: https://quotes.toscrape.com/tag/misattributed-to-c-s-lewis/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/reading-books/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/learning/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/read/page/1/\n",
      "Scraping: https://quotes.toscrape.com/author/George-R-R-Martin\n",
      "Scraping: https://quotes.toscrape.com/tag/misattributed-to-mother-teresa/page/1/\n",
      "Scraping: https://quotes.toscrape.com/author/Mother-Teresa\n",
      "Scraping: https://quotes.toscrape.com/tag/romance/page/1/\n",
      "Scraping: https://quotes.toscrape.com/author/Stephenie-Meyer\n",
      "Scraping: https://quotes.toscrape.com/tag/drug/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/self-indulgence/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/chocolate/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/open-mind/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/food/page/1/\n",
      "Scraping: https://quotes.toscrape.com/author/Garrison-Keillor\n",
      "Scraping: https://quotes.toscrape.com/author/Charles-M-Schulz\n",
      "Scraping: https://quotes.toscrape.com/tag/truth/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/insanity/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/lying/page/1/\n",
      "Scraping: https://quotes.toscrape.com/author/Jim-Henson\n",
      "Scraping: https://quotes.toscrape.com/tag/religion/page/1/\n",
      "Scraping: https://quotes.toscrape.com/author/Suzanne-Collins\n",
      "Scraping: https://quotes.toscrape.com/tag/humor/page/2/\n",
      "Scraping: https://quotes.toscrape.com/author/George-Carlin\n",
      "Scraping: https://quotes.toscrape.com/author/Charles-Bukowski\n",
      "Scraping: https://quotes.toscrape.com/author/Terry-Pratchett\n",
      "Scraping: https://quotes.toscrape.com/tag/lies/page/1/\n",
      "Scraping: https://quotes.toscrape.com/author/George-Bernard-Shaw\n",
      "Scraping: https://quotes.toscrape.com/tag/yourself/page/1/\n",
      "Scraping: https://quotes.toscrape.com/author/Ralph-Waldo-Emerson\n",
      "Scraping: https://quotes.toscrape.com/tag/comedy/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/regrets/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/life/page/2/\n",
      "Scraping: https://quotes.toscrape.com/author/Alfred-Tennyson\n",
      "Scraping: https://quotes.toscrape.com/tag/misattributed-mark-twain/page/1/\n",
      "Scraping: https://quotes.toscrape.com/author/J-M-Barrie\n",
      "Scraping: https://quotes.toscrape.com/tag/women/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/romantic/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/adventure/page/1/\n",
      "Scraping: https://quotes.toscrape.com/author/Jimi-Hendrix\n",
      "Scraping: https://quotes.toscrape.com/tag/dreamers/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/dreams/page/1/\n",
      "Scraping: https://quotes.toscrape.com/author/John-Lennon\n",
      "Scraping: https://quotes.toscrape.com/tag/dreaming/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/connection/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/peace/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/beatles/page/1/\n",
      "Scraping: https://quotes.toscrape.com/author/E-E-Cummings\n",
      "Scraping: https://quotes.toscrape.com/tag/attributed-no-source/page/1/\n",
      "Scraping: https://quotes.toscrape.com/page/4/\n",
      "Scraping: https://quotes.toscrape.com/tag/fairy-tales/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/imagination/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/music/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/happiness/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/mind/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/good/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/understanding/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/wisdom/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/knowledge/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/christianity/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/sun/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/faith/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/sinister/page/1/\n",
      "Scraping: https://quotes.toscrape.com/author/W-C-Fields\n",
      "Scraping: https://quotes.toscrape.com/author/Khaled-Hosseini\n",
      "Scraping: https://quotes.toscrape.com/tag/dumbledore/page/1/\n",
      "Scraping: https://quotes.toscrape.com/page/5/\n",
      "Scraping: https://quotes.toscrape.com/page/6/\n",
      "Scraping: https://quotes.toscrape.com/tag/misattributed-to-einstein/page/1/\n",
      "Scraping: https://quotes.toscrape.com/page/7/\n",
      "Scraping: https://quotes.toscrape.com/tag/inspiration/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/fear/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/attributed/page/1/\n",
      "Scraping: https://quotes.toscrape.com/author/Alexandre-Dumas-fils\n",
      "Scraping: https://quotes.toscrape.com/author/J-R-R-Tolkien\n",
      "Scraping: https://quotes.toscrape.com/tag/bilbo/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/journey/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/live-death-love/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/lost/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/travel/page/1/\n",
      "Scraping: https://quotes.toscrape.com/page/8/\n",
      "Scraping: https://quotes.toscrape.com/tag/the-hunger-games/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/quest/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/wander/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/alcohol/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/education/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/troubles/page/1/\n",
      "Scraping: https://quotes.toscrape.com/page/9/\n",
      "Scraping: https://quotes.toscrape.com/author/Ayn-Rand\n",
      "Scraping: https://quotes.toscrape.com/tag/age/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/mistakes/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/fairytales/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/jane-austen/page/1/\n",
      "Scraping: https://quotes.toscrape.com/page/10/\n",
      "Scraping: https://quotes.toscrape.com/tag/integrity/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/growing-up/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/elizabeth-bennet/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/god/page/1/\n",
      "Scraping: https://quotes.toscrape.com/tag/better-life-empathy/page/1/\n",
      "Scraping: https://quotes.toscrape.com/author/Harper-Lee\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import requests\n",
    "from urllib.parse import urljoin, urlparse\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "class RobotsParser:\n",
    "    def __init__(self, base_url):\n",
    "        self.base_url = base_url\n",
    "        self.allowed_paths = set()\n",
    "        self.disallowed_paths = set()\n",
    "        self.parse_robots_txt()\n",
    "\n",
    "    def parse_robots_txt(self):\n",
    "        robots_url = urljoin(self.base_url, \"robots.txt\")\n",
    "        try:\n",
    "            response = requests.get(robots_url, timeout=5)\n",
    "            if response.status_code == 200:\n",
    "                lines = response.text.splitlines()\n",
    "                for line in lines:\n",
    "                    if line.startswith(\"Disallow:\"):\n",
    "                        path = line[len(\"Disallow:\"):].strip()\n",
    "                        self.disallowed_paths.add(path)\n",
    "                    elif line.startswith(\"Allow:\"):\n",
    "                        path = line[len(\"Allow:\"):].strip()\n",
    "                        self.allowed_paths.add(path)\n",
    "        except requests.exceptions.RequestException:\n",
    "            print(f\"Failed to fetch robots.txt from {robots_url}. Assuming full access.\")\n",
    "\n",
    "    def is_allowed(self, url_path):\n",
    "        for disallowed_path in self.disallowed_paths:\n",
    "            if url_path.startswith(disallowed_path):\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "\n",
    "class MultiThreadedScraper:\n",
    "    def __init__(self, base_url, max_threads=5):\n",
    "        self.base_url = base_url\n",
    "        self.visited_urls = set()  # URLs we've visited\n",
    "        self.queue = []  # URLs we still need to scrape\n",
    "        self.lock = threading.Lock()  # Lock for thread safety\n",
    "        self.robots_parser = RobotsParser(base_url)  # Respect robots.txt\n",
    "        self.max_threads = max_threads\n",
    "        self.found_urls = []  # List to store the scraped URLs\n",
    "\n",
    "    def fetch_url(self, url):\n",
    "        \"\"\" Fetch the content of the URL. \"\"\"\n",
    "        try:\n",
    "            response = requests.get(url, timeout=5)\n",
    "            if response.status_code == 200:\n",
    "                return response.text\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error fetching {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "    def parse_links(self, url, html):\n",
    "        \"\"\" Parse the HTML to extract links. \"\"\"\n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "        links = set()\n",
    "        for a_tag in soup.find_all(\"a\", href=True):\n",
    "            full_url = urljoin(self.base_url, a_tag[\"href\"])\n",
    "            parsed_url = urlparse(full_url)\n",
    "            if parsed_url.netloc == urlparse(self.base_url).netloc:  # Same domain\n",
    "                links.add(full_url)\n",
    "        return links\n",
    "\n",
    "    def scrape_url(self, url):\n",
    "        \"\"\" Scrape the URL and extract links. \"\"\"\n",
    "        with self.lock:\n",
    "            if url in self.visited_urls:\n",
    "                return\n",
    "            self.visited_urls.add(url)\n",
    "\n",
    "        print(f\"Scraping: {url}\")\n",
    "        self.found_urls.append(url)  # Store the visited URL in found_urls\n",
    "        html = self.fetch_url(url)\n",
    "        if html:\n",
    "            links = self.parse_links(url, html)\n",
    "            with self.lock:\n",
    "                for link in links:\n",
    "                    if link not in self.visited_urls and self.robots_parser.is_allowed(urlparse(link).path):\n",
    "                        self.queue.append(link)\n",
    "\n",
    "    def worker(self):\n",
    "        \"\"\" Worker thread that processes the queue of URLs. \"\"\"\n",
    "        while True:\n",
    "            with self.lock:\n",
    "                if not self.queue:\n",
    "                    return\n",
    "                url = self.queue.pop(0)\n",
    "\n",
    "            self.scrape_url(url)\n",
    "\n",
    "    def save_to_csv(self, filename=\"scraped_urls.csv\"):\n",
    "        \"\"\" Save the found URLs to a CSV file. \"\"\"\n",
    "        with open(filename, \"w\", newline=\"\") as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"Scraped URLs\"])  # CSV Header\n",
    "            for url in self.found_urls:\n",
    "                writer.writerow([url])\n",
    "\n",
    "    def save_to_text_file(self, filename=\"scraped_urls.txt\"):\n",
    "        \"\"\" Save the found URLs to a text file. \"\"\"\n",
    "        with open(filename, \"w\") as file:\n",
    "            for url in self.found_urls:\n",
    "                file.write(url + \"\\n\")\n",
    "\n",
    "    def run(self, start_path=\"/\"):\n",
    "        \"\"\" Start scraping from the given start path. \"\"\"\n",
    "        self.queue.append(urljoin(self.base_url, start_path))\n",
    "        threads = []\n",
    "\n",
    "        for _ in range(self.max_threads):\n",
    "            t = threading.Thread(target=self.worker)\n",
    "            threads.append(t)\n",
    "            t.start()\n",
    "\n",
    "        for t in threads:\n",
    "            t.join()\n",
    "\n",
    "        # After scraping, save the results to both CSV and text files\n",
    "        self.save_to_csv()  # Save URLs to CSV\n",
    "        self.save_to_text_file()  # Save URLs to text file\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    base_url = \"https://quotes.toscrape.com/\"  # Replace with the website URL you want to scrape\n",
    "    scraper = MultiThreadedScraper(base_url, max_threads=5)\n",
    "    scraper.run(start_path=\"/\")  # Start scraping from the homepage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b8cf45-85d9-4aa2-9c32-2d88693291fc",
   "metadata": {},
   "source": [
    "#### 5. Implement a thread safe priority queue"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5e63f3f6-1b65-4744-a428-300981eba059",
   "metadata": {},
   "source": [
    "# Priority queue:\n",
    "- Priority queue are a data structure where operation is carried out on the basis of the priority\n",
    "- lower the value, higher the priority\n",
    "\n",
    "# Thread-Safe Data structure:\n",
    "- A thread safe data structures can safely handle access from multiple threads at the same time\n",
    "- without thread-safety simultaneous reads and writes can lead to race conditions and corrupted data\n",
    "- the queue.PriorityQueue class in python is inherently thread safe, meaning ou dont need to implement extra locking mechanism using it\n",
    "\n",
    "# Modules required:\n",
    "- threading: provides tools from creating and manging threads\n",
    "- PriorityQueue from queue: pre impleneted functionality relatid to threading and pririty queue\n",
    "- time: used to simulate delays\n",
    "- random: used to generate random priorities and delays for variety in the program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81eea715-d58b-4e77-9497-b81568f6e9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Producer-0 enqueueing: Item-0 from Producer-0 with priority 3\n",
      "Producer-1 enqueueing: Item-0 from Producer-1 with priority 5\n",
      "Consumer-0 dequeued: Item-0 from Producer-0 with priority 3\n",
      "Consumer-1 dequeued: Item-0 from Producer-1 with priority 5\n",
      "Consumer-1 waiting for items...\n",
      "Consumer-1 waiting for items...\n",
      "Producer-1 enqueueing: Item-1 from Producer-1 with priority 10\n",
      "Producer-0 enqueueing: Item-1 from Producer-0 with priority 9\n",
      "Consumer-0 dequeued: Item-1 from Producer-0 with priority 9\n",
      "Producer-1 enqueueing: Item-2 from Producer-1 with priority 8\n",
      "Consumer-1 dequeued: Item-2 from Producer-1 with priority 8\n",
      "Producer-1 enqueueing: Item-3 from Producer-1 with priority 8\n",
      "Producer-0 enqueueing: Item-2 from Producer-0 with priority 4\n",
      "Consumer-0 dequeued: Item-2 from Producer-0 with priority 4\n",
      "Producer-0 enqueueing: Item-3 from Producer-0 with priority 9\n",
      "Producer-1 enqueueing: Item-4 from Producer-1 with priority 8\n",
      "Consumer-1 dequeued: Item-3 from Producer-1 with priority 8\n",
      "Consumer-0 dequeued: Item-4 from Producer-1 with priority 8\n",
      "Producer-0 enqueueing: Item-4 from Producer-0 with priority 5\n",
      "Consumer-1 dequeued: Item-4 from Producer-0 with priority 5\n",
      "Consumer-0 dequeued: Item-3 from Producer-0 with priority 9\n",
      "Consumer-1 dequeued: Item-1 from Producer-1 with priority 10\n",
      "Consumer-0 waiting for items...\n",
      "Consumer-1 waiting for items...\n",
      "Consumer-0 waiting for items...\n",
      "Consumer-1 waiting for items...\n",
      "Consumer-1 waiting for items...\n",
      "Consumer-0 waiting for items...\n",
      "Consumer-1 waiting for items...\n",
      "Consumer-1 waiting for items...\n",
      "Consumer-0 waiting for items...\n",
      "Consumer-0 waiting for items...\n",
      "Consumer-1 waiting for items...\n",
      "Consumer-1 waiting for items...\n",
      "Consumer-0 waiting for items...\n",
      "Consumer-1 waiting for items...\n",
      "Consumer-0 waiting for items...\n",
      "Stopping consumers...\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "from queue import PriorityQueue\n",
    "import time\n",
    "import random\n",
    "\n",
    "class ThreadSafePriorityQueue:\n",
    "    def __init__(self):\n",
    "        # Initialize a PriorityQueue\n",
    "        self.pq = PriorityQueue()\n",
    "\n",
    "    def enqueue(self, priority, item):\n",
    "        \"\"\"Add an item to the priority queue with a given priority.\"\"\"\n",
    "        self.pq.put((priority, item))\n",
    "\n",
    "    def dequeue(self):\n",
    "        \"\"\"Remove and return the highest-priority item.\"\"\"\n",
    "        is_empty = self.is_empty()\n",
    "        if not is_empty:\n",
    "            return self.pq.get()\n",
    "        return None\n",
    "\n",
    "    def is_empty(self):\n",
    "        \"\"\"Check if the queue is empty.\"\"\"\n",
    "        return self.pq.empty()\n",
    "\n",
    "# Worker function for producer threads\n",
    "def producer(queue, producer_id):\n",
    "    for i in range(5):\n",
    "        priority = random.randint(1, 10)  # Generate a random priority\n",
    "        item = f\"Item-{i} from Producer-{producer_id}\"\n",
    "        print(f\"Producer-{producer_id} enqueueing: {item} with priority {priority}\")\n",
    "        queue.enqueue(priority, item)\n",
    "        time.sleep(random.random())  # Simulate variable processing time\n",
    "\n",
    "# Worker function for consumer threads\n",
    "def consumer(queue, consumer_id):\n",
    "    while True:\n",
    "        if not queue.is_empty():\n",
    "            priority, item = queue.dequeue()\n",
    "            print(f\"Consumer-{consumer_id} dequeued: {item} with priority {priority}\")\n",
    "        else:\n",
    "            print(f\"Consumer-{consumer_id} waiting for items...\")\n",
    "        time.sleep(random.random())  # Simulate variable processing time\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    # Create a thread-safe priority queue\n",
    "    priority_queue = ThreadSafePriorityQueue()\n",
    "\n",
    "    # Start producer threads\n",
    "    producers = [threading.Thread(target=producer, args=(priority_queue, i)) for i in range(2)]\n",
    "\n",
    "    # Start consumer threads\n",
    "    consumers = [threading.Thread(target=consumer, args=(priority_queue, i)) for i in range(2)]\n",
    "\n",
    "    # Start all threads\n",
    "    for p in producers:\n",
    "        p.start()\n",
    "    for c in consumers:\n",
    "        c.start()\n",
    "\n",
    "    # Wait for producers to finish\n",
    "    for p in producers:\n",
    "        p.join()\n",
    "\n",
    "    # Let consumers run for a while and then terminate\n",
    "    time.sleep(5)\n",
    "    print(\"Stopping consumers...\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b155919-868d-440d-9a51-28abf5b005bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
